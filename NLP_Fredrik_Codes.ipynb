{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "\n",
    "# Compulsory Assignment 2 \n",
    "\n",
    "## Natural Language Processing [KAN - CSCO1002U]\n",
    "<center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  0. Importing Modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "import gensim.downloader as api\n",
    "import nltk\n",
    "import re\n",
    "import gensim\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize, WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing the Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             article  topic  publication\n",
      "0  intention presidentelect donald trump put end ...      7            1\n",
      "1  board member uber arianna huffington active tr...      2            1\n",
      "2  live blog european stock type live eikon news ...      7            1\n",
      "3  peter bergen national security analyst vice pr...      7            3\n",
      "4  m scott lutheran pastor one recent morning hap...      7            2\n",
      "   publication                                            article  topic\n",
      "0            2  fiat chrysler autombiles recalling jeep wrangl...      2\n",
      "1            1  ottawa march china provided scientific evidenc...      2\n",
      "2            1  cybersecurity company started two former natio...      2\n",
      "3            2  washington federal aviation administration sai...      2\n",
      "4            1  san francisco last october angellist company h...      2\n"
     ]
    }
   ],
   "source": [
    "# Importing training and test set \n",
    "train = pd.read_csv(\"C:/Users/fredr/OneDrive/Documents/Master/Semester_2/NLP/Project/train.csv\")\n",
    "test = pd.read_csv(\"C:/Users/fredr/OneDrive/Documents/Master/Semester_2/NLP/Project/test.csv\")\n",
    "print(test.head())\n",
    "print(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 342876 entries, 0 to 342875\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count   Dtype \n",
      "---  ------       --------------   ----- \n",
      " 0   publication  342876 non-null  int64 \n",
      " 1   article      342876 non-null  object\n",
      " 2   topic        342876 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 7.8+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41183 entries, 0 to 41182\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   article      41183 non-null  object\n",
      " 1   topic        41183 non-null  int64 \n",
      " 2   publication  41183 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 965.4+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(train.info())\n",
    "print(test.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a sample \n",
    "train = train.sample(n=5000, random_state = 9)\n",
    "test = test.sample(n=1000, random_state = 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffeling the data \n",
    "train = train.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Word Embeddings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Bag of Words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CountVectorizer()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CountVectorizer \n",
    "BoW = CountVectorizer()\n",
    "BoW.fit(train['article'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Word2Vect - Trained on our own data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Got codes from: \n",
    "https://spotintelligence.com/2023/02/15/word2vec-for-text-classification/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing the cleaned text\n",
    "train_text = train['article']\n",
    "train_tokens = train_text.apply(word_tokenize)\n",
    "\n",
    "test_text = test['article']\n",
    "test_tokens = test_text.apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the Word2Vec model \n",
    "wvT = Word2Vec(train_tokens, \n",
    "               vector_size = 100, \n",
    "               window = 5, \n",
    "               min_count = 2, \n",
    "               workers = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for vectorizing the text\n",
    "def vectorize(tokens):\n",
    "    words = tokens.split()\n",
    "    words_vecs = [wvT.wv[word] for word in words if word in wvT.wv]\n",
    "    if len(words_vecs) == 0:\n",
    "        return np.zeros(100)\n",
    "    words_vecs = np.array(words_vecs)\n",
    "    return words_vecs.mean(axis=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Word2Vec - Trained by Google"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Got codes from Exercise Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google trained one \n",
    "wvG = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for computing the average vector \n",
    "# Gathered from Exercise 8\n",
    "\n",
    "def avg_feature_vector(words, model, num_features):\n",
    "    n_words = 0\n",
    "    feature_vec = np.zeros((num_features, ), dtype='float32')\n",
    "    for word in words:\n",
    "        try:\n",
    "            n_words += 1\n",
    "            feature_vec = np.add(feature_vec, model[word])\n",
    "        except KeyError:\n",
    "            pass\n",
    "    if n_words == 0:\n",
    "        return feature_vec\n",
    "    else:\n",
    "        return feature_vec / n_words\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Text Classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation function that prints classification report and confusion matrix\n",
    "def evaluate(y_test, y_pred, model_name):\n",
    "    '''\n",
    "    Function for Evaluating a model\n",
    "    Prints out:\n",
    "    --- Classification Report \n",
    "    --- Confusion Matrix\n",
    "    '''\n",
    "    \n",
    "    print(f\"\\033[34m{model_name}\\033[0m\")\n",
    "    \n",
    "    #print Classification Report and Accuracy\n",
    "    print(f\" \\033[32mClassification Report:\\033[0m\")\n",
    "    print(classification_report(y_test, y_pred, zero_division=False))\n",
    "    print(f\" \\033[32mAccuracy Score:\\033[0m\")\n",
    "    print(accuracy_score(y_test, y_pred)*100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Baseline Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.1 Logistic Regression with Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting features and content\n",
    "y_test = test['publication']\n",
    "y_train = train['publication']\n",
    "X_test = test['article']\n",
    "X_train = train['article']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mLogistic Regression with BoW\u001b[0m\n",
      " \u001b[32mClassification Report:\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.77      0.79       335\n",
      "           2       0.91      0.73      0.81       296\n",
      "           3       0.76      0.68      0.72       254\n",
      "           4       0.50      0.80      0.62        56\n",
      "           5       0.71      1.00      0.83        39\n",
      "           6       0.22      0.80      0.34        20\n",
      "\n",
      "    accuracy                           0.75      1000\n",
      "   macro avg       0.65      0.80      0.68      1000\n",
      "weighted avg       0.80      0.75      0.76      1000\n",
      "\n",
      " \u001b[32mAccuracy Score:\u001b[0m\n",
      "74.7\n"
     ]
    }
   ],
   "source": [
    "# Vectorizer \n",
    "X_train_bow = BoW.transform(X_train)\n",
    "X_test_bow = BoW.transform(X_test)\n",
    "\n",
    "# Classifier \n",
    "lr_bow = LogisticRegression(max_iter=1000000)\n",
    "lr_bow.fit(X_train_bow, y_train)\n",
    "\n",
    "# Evaluate\n",
    "yPred_lr_bow = lr_bow.predict(X_test_bow)\n",
    "evaluate(y_test, yPred_lr_bow, 'Logistic Regression with BoW')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix_bow = confusion_matrix(y_test, yPred_lr_bow)\n",
    "classes_bow = np.unique(y_test)\n",
    "cm_display = ConfusionMatrixDisplay(confusion_matrix = confusion_matrix_bow, display_labels = classes_bow)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2 Random Forest with Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mRandom Forest with BoW\u001b[0m\n",
      " \u001b[32mClassification Report:\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.81      0.80       335\n",
      "           2       0.84      0.70      0.76       296\n",
      "           3       0.72      0.69      0.70       254\n",
      "           4       0.79      0.80      0.80        56\n",
      "           5       0.88      0.97      0.93        39\n",
      "           6       0.23      0.80      0.35        20\n",
      "\n",
      "    accuracy                           0.75      1000\n",
      "   macro avg       0.71      0.80      0.72      1000\n",
      "weighted avg       0.78      0.75      0.76      1000\n",
      "\n",
      " \u001b[32mAccuracy Score:\u001b[0m\n",
      "75.1\n"
     ]
    }
   ],
   "source": [
    "# Classifier \n",
    "rf_bow = RandomForestClassifier()\n",
    "rf_bow.fit(X_train_bow, y_train)\n",
    "\n",
    "# Evaluate\n",
    "yPred_rf_bow = rf_bow.predict(X_test_bow)\n",
    "evaluate(y_test, yPred_rf_bow, 'Random Forest with BoW')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.3 Logistic Regression with own trained Word2Vec embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorizing\n",
    "X_train_wvT = np.array([vectorize(train_tokens) for train_tokens in X_train])\n",
    "X_test_wvT = np.array([vectorize(train_tokens) for train_tokens in X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mLogisitic Regression with own W2V\u001b[0m\n",
      " \u001b[32mClassification Report:\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.67      0.74       335\n",
      "           2       0.84      0.55      0.66       296\n",
      "           3       0.59      0.60      0.60       254\n",
      "           4       0.26      0.55      0.35        56\n",
      "           5       0.47      0.97      0.64        39\n",
      "           6       0.16      0.60      0.26        20\n",
      "\n",
      "    accuracy                           0.62      1000\n",
      "   macro avg       0.52      0.66      0.54      1000\n",
      "weighted avg       0.71      0.62      0.65      1000\n",
      "\n",
      " \u001b[32mAccuracy Score:\u001b[0m\n",
      "62.1\n"
     ]
    }
   ],
   "source": [
    "# Classifier \n",
    "lr_wvT = LogisticRegression(max_iter=1000000)\n",
    "lr_wvT.fit(X_train_wvT, y_train)\n",
    "\n",
    "# Evaluate\n",
    "yPred_lr_wvT = lr_wvT.predict(X_test_wvT)\n",
    "evaluate(y_test, yPred_lr_wvT, 'Logisitic Regression with own W2V')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix_wvt = confusion_matrix(y_test, yPred_lr_wvT)\n",
    "classes_bow = np.unique(y_test)\n",
    "cm_display = ConfusionMatrixDisplay(confusion_matrix = confusion_matrix_wvt, display_labels = classes_bow)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.4 Random Forest with own trained Word2Vec embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mRandom Forest with own W2V\u001b[0m\n",
      " \u001b[32mClassification Report:\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.67      0.74       335\n",
      "           2       0.76      0.43      0.55       296\n",
      "           3       0.63      0.66      0.64       254\n",
      "           4       0.24      0.48      0.32        56\n",
      "           5       0.36      0.90      0.51        39\n",
      "           6       0.09      0.40      0.15        20\n",
      "\n",
      "    accuracy                           0.59      1000\n",
      "   macro avg       0.48      0.59      0.48      1000\n",
      "weighted avg       0.69      0.59      0.61      1000\n",
      "\n",
      " \u001b[32mAccuracy Score:\u001b[0m\n",
      "58.699999999999996\n"
     ]
    }
   ],
   "source": [
    "# Classifier \n",
    "rf_wvT = RandomForestClassifier()\n",
    "rf_wvT.fit(X_train_wvT, y_train)\n",
    "\n",
    "# Evaluate\n",
    "yPred_rf_wvT = rf_wvT.predict(X_test_wvT)\n",
    "evaluate(y_test, yPred_rf_wvT, 'Random Forest with own W2V')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.3 Logistic Regression with Google trained Word2Vec embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constructing average vectors \n",
    "train_features = []\n",
    "vectorsize = 300\n",
    "for t in train_tokens:\n",
    "    train_features.append(avg_feature_vector(t, wvG, vectorsize))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = []\n",
    "vectorsize = 300\n",
    "for t in test_tokens:\n",
    "    test_features.append(avg_feature_vector(t, wvG, vectorsize))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data \n",
    "X_train_wvG = train_features\n",
    "X_test_wvG = test_features\n",
    "y_train_wvG = train['publication']\n",
    "y_test_wvG = test['publication']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mLogistic Regression with Google W2V\u001b[0m\n",
      " \u001b[32mClassification Report:\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.64      0.72       335\n",
      "           2       0.83      0.40      0.54       296\n",
      "           3       0.61      0.61      0.61       254\n",
      "           4       0.26      0.52      0.34        56\n",
      "           5       0.31      0.95      0.47        39\n",
      "           6       0.12      0.60      0.19        20\n",
      "\n",
      "    accuracy                           0.57      1000\n",
      "   macro avg       0.49      0.62      0.48      1000\n",
      "weighted avg       0.70      0.57      0.60      1000\n",
      "\n",
      " \u001b[32mAccuracy Score:\u001b[0m\n",
      "56.699999999999996\n"
     ]
    }
   ],
   "source": [
    "# Classifier  \n",
    "lr_wvG = LogisticRegression(max_iter=1000000)\n",
    "lr_wvG.fit(X_train_wvG, y_train_wvG)\n",
    "\n",
    "# Evaluate\n",
    "yPred_lr_wvG = lr_wvG.predict(X_test_wvG)\n",
    "evaluate(y_test_wvG, yPred_lr_wvG, 'Logistic Regression with Google W2V')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.5 Random Forest with Google trained Word2Vec embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mRandom Forest with Google W2V\u001b[0m\n",
      " \u001b[32mClassification Report:\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.63      0.70       335\n",
      "           2       0.69      0.42      0.52       296\n",
      "           3       0.60      0.59      0.59       254\n",
      "           4       0.24      0.52      0.33        56\n",
      "           5       0.30      0.82      0.44        39\n",
      "           6       0.10      0.45      0.17        20\n",
      "\n",
      "    accuracy                           0.55      1000\n",
      "   macro avg       0.46      0.57      0.46      1000\n",
      "weighted avg       0.65      0.55      0.58      1000\n",
      "\n",
      " \u001b[32mAccuracy Score:\u001b[0m\n",
      "55.2\n"
     ]
    }
   ],
   "source": [
    "# Classifier \n",
    "rf_wvG = RandomForestClassifier()\n",
    "rf_wvG.fit(X_train_wvG, y_train_wvG)\n",
    "\n",
    "# Evaluate \n",
    "yPred_rf_wvG = rf_wvG.predict(X_test_wvG)\n",
    "evaluate(y_test_wvG, yPred_rf_wvG, 'Random Forest with Google W2V')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
